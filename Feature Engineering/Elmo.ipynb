{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Elmo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "tFWIKTtQz636",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E8vdlr5k0Sbx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7d205ef7-96cb-4041-8df8-14b5da8a8393"
      },
      "cell_type": "code",
      "source": [
        "!free -m"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:          13022        3346        5546         265        4129       10932\n",
            "Swap:             0           0           0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AwCm-gGF0fCz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import keras.layers as layers\n",
        "\n",
        "from collections import Counter\n",
        "from keras import backend as K\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.layers import Input, Embedding, BatchNormalization, LSTM, Dense, Concatenate\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.utils import plot_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9ppIuZBGAx95",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "32444e96-4183-4523-a238-6cccf9c1e3bd"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SPHADqj203mG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reliable = pd.read_csv('drive/My Drive/CSV/reliable_mini.csv').drop(columns = ['title', 'authors'])\n",
        "fake = pd.read_csv('drive/My Drive/CSV/fake_mini.csv').drop(columns = ['title','authors'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8y3c8A3N1FkP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "type_dic = {'fake': 0, 'reliable':1}\n",
        "f = lambda x:type_dic[x]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IBG98NGY1HkR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reliable['type'] = reliable['type'].apply(f)\n",
        "fake['type'] = fake['type'].apply(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rjQxpgEY2pH0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df = reliable[:6000]\n",
        "train_df = pd.concat([train_df,fake[:6000]])\n",
        "train_df.reset_index(drop = True,inplace = True)\n",
        "                      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lGdlieYt288B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_df = reliable[6000:]\n",
        "test_df = pd.concat([test_df,fake[6000:]])\n",
        "test_df.reset_index(drop = True,inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UbMhrNTt2_Kk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5e42c121-835b-42e3-fa04-f2f5bcd11df0"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "test_df['type'].value_counts()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    4000\n",
              "0    4000\n",
              "Name: type, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "TLetyYGT5nHV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fbb75151-87ad-4e53-caeb-30570f9f0b9f"
      },
      "cell_type": "code",
      "source": [
        "train_df['type'].value_counts()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    6000\n",
              "0    6000\n",
              "Name: type, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "OL6-eyv03Q8Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# parameter of max word length\n",
        "time_steps = 100\n",
        "\n",
        "\n",
        "# building vocabulary from dataset\n",
        "def build_vocabulary(sentence_list):\n",
        "    unique_words = \" \".join(sentence_list).strip().split()\n",
        "    word_count = Counter(unique_words).most_common()\n",
        "    vocabulary = {}\n",
        "    for word, _ in word_count:\n",
        "        vocabulary[word] = len(vocabulary)        \n",
        "\n",
        "    return vocabulary\n",
        "\n",
        "\n",
        "# Get vocabulary vectors from document list\n",
        "# Vocabulary vector, Unknown word is 1 and padding is 0\n",
        "# INPUT: raw sentence list\n",
        "# OUTPUT: vocabulary vectors list\n",
        "def get_voc_vec(document_list, vocabulary):    \n",
        "    voc_ind_sentence_list = []\n",
        "    for document in document_list:\n",
        "        voc_idx_sentence = []\n",
        "        word_list = document.split()\n",
        "        \n",
        "        for w in range(time_steps):\n",
        "            if w < len(word_list):\n",
        "                # pickup vocabulary id and convert unknown word into 1\n",
        "                voc_idx_sentence.append(vocabulary.get(word_list[w], -1) + 2)\n",
        "            else:\n",
        "                # padding with 0\n",
        "                voc_idx_sentence.append(0)\n",
        "            \n",
        "        voc_ind_sentence_list.append(voc_idx_sentence)\n",
        "        \n",
        "    return np.array(voc_ind_sentence_list)\n",
        "\n",
        "\n",
        "vocabulary = build_vocabulary(train_df['content'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cixcUk0u3pjs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Reduce TensorFlow logging output.\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "# Instantiate the elmo model\n",
        "elmo_module = hub.Module(\"https://tfhub.dev/google/elmo/1\", trainable=False)\n",
        "\n",
        "# Initialize session\n",
        "sess = tf.Session()\n",
        "K.set_session(sess)\n",
        "\n",
        "K.set_learning_phase(1)\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(tf.tables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VOLs7zGe36rp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# mini-batch generator\n",
        "def batch_iter(data, labels, batch_size, shuffle=True):\n",
        "    num_batches_per_epoch = int((len(data) - 1) / batch_size) + 1\n",
        "    print(\"batch_size\", batch_size)\n",
        "    print(\"num_batches_per_epoch\", num_batches_per_epoch)\n",
        "\n",
        "    def data_generator():\n",
        "        data_size = len(data)\n",
        "\n",
        "        while True:\n",
        "            # Shuffle the data at each epoch\n",
        "            if shuffle:\n",
        "                shuffle_indices = np.random.permutation(np.arange(data_size))\n",
        "                shuffled_data = data[shuffle_indices]\n",
        "                shuffled_labels = labels[shuffle_indices]\n",
        "            else:\n",
        "                shuffled_data = data\n",
        "                shuffled_labels = labels\n",
        "\n",
        "            for batch_num in range(num_batches_per_epoch):\n",
        "                start_index = batch_num * batch_size\n",
        "                end_index = min((batch_num + 1) * batch_size, data_size)\n",
        "                                \n",
        "                X_voc = get_voc_vec(shuffled_data[start_index: end_index], vocabulary)\n",
        "                                \n",
        "                sentence_split_list = []\n",
        "                sentence_split_length_list = []\n",
        "            \n",
        "                for sentence in shuffled_data[start_index: end_index]:    \n",
        "                    sentence_split = sentence.split()\n",
        "                    sentence_split_length = len(sentence_split)\n",
        "                    sentence_split += [\"NaN\"] * (time_steps - sentence_split_length)\n",
        "                    \n",
        "                    sentence_split_list.append((\" \").join(sentence_split))\n",
        "                    sentence_split_length_list.append(sentence_split_length)\n",
        "        \n",
        "                X_elmo = np.array(sentence_split_list)\n",
        "\n",
        "                X = [X_voc, X_elmo]\n",
        "                y = shuffled_labels[start_index: end_index]\n",
        "                \n",
        "                yield X, y\n",
        "\n",
        "    return num_batches_per_epoch, data_generator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z-D6dpvC4Q47",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# embed elmo method\n",
        "def make_elmo_embedding(x):\n",
        "    embeddings = elmo_module(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"elmo\"]\n",
        "    \n",
        "    return embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gSq-SC934WFH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "9ccce35b-d7c7-4992-ccca-45da41bc8b2f"
      },
      "cell_type": "code",
      "source": [
        "# elmo embedding dimension\n",
        "elmo_dim = 1024\n",
        "\n",
        "# Input Layers\n",
        "word_input = Input(shape=(None, ), dtype='int32')  # (batch_size, sent_length)\n",
        "elmo_input = Input(shape=(None, ), dtype=\"string\") #we change 'tf.string)'  # (batch_size, sent_length, elmo_size)\n",
        "\n",
        "# Hidden Layers\n",
        "word_embedding = Embedding(input_dim=len(vocabulary), output_dim=128, mask_zero=True)(word_input)\n",
        "elmo_embedding = layers.Lambda(make_elmo_embedding, output_shape=(None, elmo_dim))(elmo_input)\n",
        "word_embedding = Concatenate()([word_embedding, elmo_embedding])\n",
        "word_embedding = BatchNormalization()(word_embedding)\n",
        "x = LSTM(128, dropout=0.2, recurrent_dropout=0.2)(word_embedding)\n",
        "\n",
        "# Output Layer\n",
        "predict = Dense(units=1, activation='sigmoid')(x)\n",
        "\n",
        "\n",
        "model = Model(inputs=[word_input, elmo_input], outputs=predict)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#plot_model(model, to_file=\"model.png\", show_shapes=True)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, None, 128)    42909056    input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, None, 1024)   0           input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, None, 1152)   0           embedding_3[0][0]                \n",
            "                                                                 lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, None, 1152)   4608        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   (None, 128)          655872      batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            129         lstm_3[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 43,569,665\n",
            "Trainable params: 43,567,361\n",
            "Non-trainable params: 2,304\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NRbg-FmP4syZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Create datasets (Only take up to time_steps words for memory)\n",
        "train_text = train_df['content'].tolist()\n",
        "train_text = [' '.join(t.split()[0:time_steps]) for t in train_text]\n",
        "train_text = np.array(train_text)\n",
        "train_label = np.array(train_df['type'].tolist())\n",
        "\n",
        "test_text = test_df['content'].tolist()\n",
        "test_text = [' '.join(t.split()[0:time_steps]) for t in test_text]\n",
        "test_text = np.array(test_text)\n",
        "test_label = np.array(test_df['type'].tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jJn6sulg6DQr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "5fa93a89-ee8a-4834-a3cd-2b4b1f51267a"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_steps, train_batches = batch_iter(train_text,\n",
        "                                        np.array(train_df['type']),\n",
        "                                        batch_size)\n",
        "valid_steps, valid_batches = batch_iter(test_text,\n",
        "                                        np.array(test_df['type']),\n",
        "                                        batch_size)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch_size 32\n",
            "num_batches_per_epoch 375\n",
            "batch_size 32\n",
            "num_batches_per_epoch 250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jjBrYKLo6QHB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "logfile_path = './log'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pmjst64P6Vbr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "763876ef-16b6-47dd-f6e1-538b2ec99f8d"
      },
      "cell_type": "code",
      "source": [
        "tb_cb = TensorBoard(log_dir=logfile_path, histogram_freq=0)\n",
        "\n",
        "history = model.fit_generator(train_batches, train_steps,\n",
        "                              epochs=5, \n",
        "                              validation_data=valid_batches,\n",
        "                              validation_steps=valid_steps,\n",
        "                              callbacks=[tb_cb])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "375/375 [==============================] - 835s 2s/step - loss: 0.2309 - acc: 0.8988 - val_loss: 0.0641 - val_acc: 0.9828\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 832s 2s/step - loss: 0.0286 - acc: 0.9912 - val_loss: 0.1539 - val_acc: 0.9476\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 831s 2s/step - loss: 0.0074 - acc: 0.9980 - val_loss: 0.0619 - val_acc: 0.9814\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 830s 2s/step - loss: 0.0028 - acc: 0.9993 - val_loss: 0.0716 - val_acc: 0.9761\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 830s 2s/step - loss: 4.9438e-04 - acc: 0.9999 - val_loss: 0.0933 - val_acc: 0.9724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Uq-3ivPt6YmM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8df0148f-5612-4c55-cd2e-833c3031d718"
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate_generator(valid_batches, valid_steps)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy;', score[1])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.12514827745070214\n",
            "Test accuracy; 0.967\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TfKaOIXkvE7u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f2f62be-61d3-47a8-a55c-424cc4285971"
      },
      "cell_type": "code",
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"drive/My Drive/model96.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"drive/My Drive/model96.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FVARXcWoj2eJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('drive/My Drive/eLMO.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5z31UepHxcoQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "87605fca-e55e-481c-c57c-d1bfe1ef394c"
      },
      "cell_type": "code",
      "source": [
        "!ls -lh drive/My\\ Drive/"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 666M\n",
            "-rw------- 1 root root 290K Feb 27  2017 'algo assignment.rar'\n",
            "drwx------ 2 root root 4.0K Jul 30 06:11  CGA\n",
            "drwx------ 2 root root 4.0K Feb  7  2018  Classroom\n",
            "drwx------ 2 root root 4.0K Oct 25 17:42 'Colab Notebooks'\n",
            "-rw------- 1 root root    1 Apr  9  2018 'Cover and Indexpage - SE.gdoc'\n",
            "drwx------ 2 root root 4.0K Oct 25 17:37  CSV\n",
            "-rw------- 1 root root    1 Apr  9  2018  EITlab_file.gdoc\n",
            "-rw------- 1 root root 499M Oct 26 14:27  eLMO.h5\n",
            "-rw------- 1 root root    1 Apr  9  2018  index.gdoc\n",
            "-rw------- 1 root root  25K Aug  5 12:19  lab1.docx\n",
            "-rw------- 1 root root  275 Aug  5 12:19  LAB_1_GE.C\n",
            "-rw------- 1 root root 3.6K Aug  5 12:19  Lab_1_px.PNG\n",
            "drwx------ 2 root root 4.0K Sep  5  2017  LabWoRk\n",
            "-rw------- 1 root root 167M Oct 26 13:28  model96.h5\n",
            "-rw------- 1 root root 6.0K Oct 26 11:55  model96.hdf5\n",
            "-rw------- 1 root root 3.9K Oct 26 13:28  model96.json\n",
            "-rw------- 1 root root    1 Apr 18  2018 'Personal_Information_Proforma - Copy.gdoc'\n",
            "-rw------- 1 root root 1.9K Oct 18  2016  Q11.txt\n",
            "-rw------- 1 root root  72K Apr 26  2018 'SE main.docx'\n",
            "-rw------- 1 root root    1 Apr 11  2018  SE_Sourabh.gdoc\n",
            "-rw------- 1 root root  18K Oct 16  2016 'SESSIONAL 2_KUK_EXAM_OCT_B.TECH - 2016.xlsx'\n",
            "-rw------- 1 root root  11K Mar 23  2018 'SE Syllabus.docx'\n",
            "-rw------- 1 root root    1 Apr 15  2017 'Untitled form.gform'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9qxojcgYxliM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1237
        },
        "outputId": "4902df17-9c22-4d5e-dba5-2ba03b2365d9"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('drive/My Drive/eLMO.h5')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-b44ec0843a24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/My Drive/eLMO.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    345\u001b[0m                         \u001b[0;34m'Maybe you meant to use '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                         '`Sequential.from_config(config)`?')\n\u001b[0;32m--> 347\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     53\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 return cls.from_config(config['config'],\n\u001b[1;32m    143\u001b[0m                                        custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n\u001b[0;32m--> 144\u001b[0;31m                                                            list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   2533\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munprocessed_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2534\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mnode_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munprocessed_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2535\u001b[0;31m                         \u001b[0mprocess_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2537\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mprocess_node\u001b[0;34m(layer, node_data)\u001b[0m\n\u001b[1;32m   2490\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2492\u001b[0;31m                     \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2493\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2494\u001b[0m                     \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0marguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mmake_elmo_embedding\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_elmo_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melmo_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"default\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"elmo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'elmo_module' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "1RhK7FDQ1LPR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}